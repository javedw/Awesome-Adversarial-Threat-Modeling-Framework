# Appendix F: Glossary and References

## Glossary

| Term | Definition |
|:---|:---|
| **AATMF** | Adversarial AI Threat Modeling Framework |
| **ASR** | Attack Success Rate — percentage of attempts that achieve the adversarial objective |
| **CaMeL** | CApability-Mediated LLM — Google DeepMind's dual-LLM security architecture |
| **CoT** | Chain-of-Thought — step-by-step reasoning in LLMs |
| **DPO** | Direct Preference Optimization — alignment training technique |
| **DRS** | Data Randomized Smoothing — defense against training data poisoning |
| **H-CoT** | Hijacked Chain-of-Thought — attack that subverts CoT safety reasoning |
| **LRM** | Large Reasoning Model — models with explicit reasoning capabilities (o1, o3, DeepSeek-R1) |
| **MCP** | Model Context Protocol — Anthropic's standard for tool integration |
| **PEFT** | Parameter-Efficient Fine-Tuning — techniques like LoRA for efficient model adaptation |
| **PUA** | Private Use Area — Unicode range used for custom characters |
| **RAG** | Retrieval-Augmented Generation — architecture combining search with generation |
| **RLHF** | Reinforcement Learning from Human Feedback — primary alignment technique |
| **SafeTensors** | Secure model serialization format that prevents code execution |
| **TEE** | Trusted Execution Environment — hardware-based security enclave |

## Key References

1. HiddenLayer. "Policy Puppetry: A Universal Jailbreak." April 2025.
2. Zeng et al. "Autonomous LRM Jailbreaking." *Nature Communications*, August 2025.
3. Xue et al. "PoisonedRAG: Knowledge Corruption Attacks." *USENIX Security 2025*.
4. Invariant Labs. "MCP-ITP: Tool Poisoning in Agentic Systems." April 2025.
5. Oligo Security. "ShadowMQ: Unsafe Deserialization in AI Inference Frameworks." November 2025.
6. Sherburn et al. "250 Documents: Universal Pretraining Backdoors." *Turing Institute/Anthropic/UK AISI*, October 2025.
7. Anthropic. "GTG-1002: AI-Orchestrated Cyber Campaign." November 2025.
8. Google DeepMind. "CaMeL: Defeating Prompt Injection by Design." March 2025.
9. Meta. "LlamaFirewall: Open-Source AI Safety Framework." April 2025.
10. MITRE. "ATLAS v4.6.0." October 2025.
11. OWASP. "LLM Top 10 2025." January 2025.
12. OWASP. "Agentic AI Top 10." December 2025.
13. NIST. "Cyber AI Profile (IR 8596) Preliminary Draft." December 2025.
14. European Parliament. "EU AI Act (Regulation 2024/1689)." 2024.
15. Qi et al. "Safety Alignment Depth." *Princeton*, May 2025.
16. Weng et al. "H-CoT: Hijacking Chain-of-Thought." *Duke/Accenture*, February 2025.
17. Borghesi et al. "SACRED-Bench: Compositional Audio Attacks." November 2025.

---

[← Appendix E](appendix-e-case-studies.md) · [Home](../../README.md)
